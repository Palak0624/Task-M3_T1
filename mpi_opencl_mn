#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>
#include <CL/cl.h>
#include <time.h>

#define N 1024
#define MAX_SOURCE_SIZE (0x100000)

const char *kernelSource = 
"__kernel void matrix_mult(__global const double *A, __global const double *B, __global double *C, int width) {\n" \
"    int row = get_global_id(0);\n" \
"    int col = get_global_id(1);\n" \
"    \n" \
"    double sum = 0.0;\n" \
"    for (int k = 0; k < width; k++) {\n" \
"        sum += A[row * width + k] * B[k * width + col];\n" \
"    }\n" \
"    C[row * width + col] = sum;\n" \
"}\n";

void initialize_matrix(double *matrix, int size) {
    for (int i = 0; i < size; i++) {
        for (int j = 0; j < size; j++) {
            matrix[i * size + j] = (double)rand() / RAND_MAX;
        }
    }
}

int main(int argc, char *argv[]) {
    int rank, size;
    double start_time, end_time;
    
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    if (N % size != 0) {
        if (rank == 0) {
            printf("Matrix size must be divisible by number of processes.\n");
        }
        MPI_Finalize();
        return 1;
    }
    
    double *A = NULL;
    double *B = NULL;
    double *C = NULL;
    double *local_A = NULL;
    double *local_C = NULL;
    
    int rows_per_process = N / size;
    
    if (rank == 0) {
        A = (double *)malloc(N * N * sizeof(double));
        B = (double *)malloc(N * N * sizeof(double));
        C = (double *)malloc(N * N * sizeof(double));
        
        initialize_matrix(A, N);
        initialize_matrix(B, N);
        
        start_time = MPI_Wtime();
    }
    
    local_A = (double *)malloc(rows_per_process * N * sizeof(double));
    local_C = (double *)malloc(rows_per_process * N * sizeof(double));
    B = (double *)malloc(N * N * sizeof(double));
    
    // Scatter rows of A to all processes
    MPI_Scatter(A, rows_per_process * N, MPI_DOUBLE, 
                local_A, rows_per_process * N, MPI_DOUBLE, 
                0, MPI_COMM_WORLD);
    
    // Broadcast B to all processes
    MPI_Bcast(B, N * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    
    // OpenCL setup
    cl_platform_id platform_id = NULL;
    cl_device_id device_id = NULL;
    cl_uint ret_num_devices;
    cl_uint ret_num_platforms;
    cl_int ret;
    
    cl_context context;
    cl_command_queue command_queue;
    cl_program program;
    cl_kernel kernel;
    cl_mem a_mem_obj, b_mem_obj, c_mem_obj;
    
    // Get platform and device information
    ret = clGetPlatformIDs(1, &platform_id, &ret_num_platforms);
    ret = clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_DEFAULT, 1, &device_id, &ret_num_devices);
    
    // Create OpenCL context
    context = clCreateContext(NULL, 1, &device_id, NULL, NULL, &ret);
    
    // Create command queue
    command_queue = clCreateCommandQueue(context, device_id, 0, &ret);
    
    // Create memory buffers on the device for each matrix
    a_mem_obj = clCreateBuffer(context, CL_MEM_READ_ONLY, rows_per_process * N * sizeof(double), NULL, &ret);
    b_mem_obj = clCreateBuffer(context, CL_MEM_READ_ONLY, N * N * sizeof(double), NULL, &ret);
    c_mem_obj = clCreateBuffer(context, CL_MEM_WRITE_ONLY, rows_per_process * N * sizeof(double), NULL, &ret);
    
    // Copy the matrices A and B to their respective memory buffers
    ret = clEnqueueWriteBuffer(command_queue, a_mem_obj, CL_TRUE, 0, 
                              rows_per_process * N * sizeof(double), local_A, 0, NULL, NULL);
    ret = clEnqueueWriteBuffer(command_queue, b_mem_obj, CL_TRUE, 0, 
                              N * N * sizeof(double), B, 0, NULL, NULL);
    
    // Create program from the kernel source
    program = clCreateProgramWithSource(context, 1, (const char **)&kernelSource, NULL, &ret);
    
    // Build the program
    ret = clBuildProgram(program, 1, &device_id, NULL, NULL, NULL);
    
    // Create the OpenCL kernel
    kernel = clCreateKernel(program, "matrix_mult", &ret);
    
    // Set the arguments of the kernel
    ret = clSetKernelArg(kernel, 0, sizeof(cl_mem), (void *)&a_mem_obj);
    ret = clSetKernelArg(kernel, 1, sizeof(cl_mem), (void *)&b_mem_obj);
    ret = clSetKernelArg(kernel, 2, sizeof(cl_mem), (void *)&c_mem_obj);
    ret = clSetKernelArg(kernel, 3, sizeof(int), (void *)&N);
    
    // Execute the OpenCL kernel on the device
    size_t global_item_size[2] = {rows_per_process, N};
    size_t local_item_size[2] = {1, 1};
    
    ret = clEnqueueNDRangeKernel(command_queue, kernel, 2, NULL, 
                                global_item_size, local_item_size, 0, NULL, NULL);
    
    // Read the memory buffer C on the device to the local variable C
    ret = clEnqueueReadBuffer(command_queue, c_mem_obj, CL_TRUE, 0, 
                             rows_per_process * N * sizeof(double), local_C, 0, NULL, NULL);
    
    // Clean up OpenCL
    ret = clFlush(command_queue);
    ret = clFinish(command_queue);
    ret = clReleaseKernel(kernel);
    ret = clReleaseProgram(program);
    ret = clReleaseMemObject(a_mem_obj);
    ret = clReleaseMemObject(b_mem_obj);
    ret = clReleaseMemObject(c_mem_obj);
    ret = clReleaseCommandQueue(command_queue);
    ret = clReleaseContext(context);
    
    // Gather results from all processes
    MPI_Gather(local_C, rows_per_process * N, MPI_DOUBLE, 
               C, rows_per_process * N, MPI_DOUBLE, 
               0, MPI_COMM_WORLD);
    
    if (rank == 0) {
        end_time = MPI_Wtime();
        printf("MPI+OpenCL Time (N=%d, %d processes): %.4f seconds\n", N, size, end_time - start_time);
        
        free(A);
        free(B);
        free(C);
    }
    
    free(local_A);
    free(local_C);
    free(B);
    
    MPI_Finalize();
    return 0;
}
